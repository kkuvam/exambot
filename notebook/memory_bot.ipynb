{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a7164-6e1d-4966-88f7-0c6459de7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb sentence-transformers openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c79426-dfe6-45a3-b3ba-a58ce1662d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import chromadb\n",
    "from chromadb import PersistentClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "import ollama\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3e057a-0129-4ee0-bd9a-46456867f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a21a98-97e0-4d2a-a75b-c864a3111f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Config\n",
    "persist_path = \"../chroma_db\"\n",
    "collection_name = \"class10_english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a2c0d2-31d7-4061-8a60-d8bcd4b8de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f978df-d038-4fad-8034-0a42edaab834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Config\n",
    "USE_OPENAI = False  # Set False to use Ollama\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "OLLAMA_MODEL = \"llama3.1\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ee137f-9f55-499a-82e2-3751bcad4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma client (üîÅ using PersistentClient)\n",
    "client = PersistentClient(path=persist_path)\n",
    "collection = client.get_or_create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4602fec0-9cfd-4247-a5e6-29fb776a396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, top_k=3):\n",
    "    embedding = model.encode([query])[0].tolist()\n",
    "    results = collection.query(query_embeddings=[embedding], n_results=top_k)\n",
    "    return results[\"documents\"][0] if results[\"documents\"] else []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3892a0de-b5c3-4edf-b7c3-9abc08bc4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(context, query):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful study tutor.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51164320-1d36-4ec3-811f-3ae4933d9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama(context, query):\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", json={\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"system\": \"You are a teacher and evaluator of class10_english\",\n",
    "        \"stream\": False\n",
    "    })\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba3e7f8-3d40-4152-b3cf-6d264586c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    return model.encode([text])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd450a3a-b2db-45da-9253-7418ffb0b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat_response(model_name, chat_history):\n",
    "    # Stream response from Ollama\n",
    "    stream = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=chat_history,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Collect streamed chunks into full response\n",
    "    assistant_response = \"\"\n",
    "    for chunk in stream:\n",
    "        chunk_content = chunk[\"message\"][\"content\"]\n",
    "        assistant_response += chunk_content\n",
    "        clear_output(wait=True)\n",
    "        # display(assistant_response)  # Display cumulative response\n",
    "        display(HTML(assistant_response.replace(\"\\n\", \"<br>\")))\n",
    "        sys.stdout.flush()  # Force flush to ensure output is shown\n",
    "    \n",
    "    # Append assistant's response to chat history\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    \n",
    "    return assistant_response, chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276438e8-39bf-405c-b632-8a619ae87058",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Teach me one of the poem from the book.\"\n",
    "chunks = retrieve_chunks(query)\n",
    "context = \"\\n\\n---\\n\\n\".join(chunks) if chunks else \"\"\n",
    "# Get answer from LLM\n",
    "answer = ask_openai(context, query) if USE_OPENAI else ask_ollama(context, query)\n",
    "print(\"üß† Q:\", query)\n",
    "print(\"üí¨ A:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb750f5-1f5d-484e-92ff-645b4145e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define context and persona and load the context\n",
    "chat_history = [{\"role\": \"system\", \"content\": f\"You are the best teacher of {collection_name}\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36b4435-dbca-47d2-8769-842893d7ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Here is the complete poem with the missing words filled in:<br><br>**Lencho's Letter to God**<br><br>Dear God!<br><br>Thank for Thank you for<br>(a) sending a hundred pesos help.<br>(b) I am very grateful for this kind gesture.<br>(c) You were my only and your love.<br>(d) help has strengthened my faith in you.<br><br>And here is the complete poem with all the missing words filled in:<br><br>**The Missing Words**<br><br>(i) Lencho thought that God would help him.<br><br>(j) Those who believe will succeed.<br><br>(k) God helps those who are true believers.<br><br>I hope this helps!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Show me the full poem\"\n",
    "chunks = retrieve_chunks(query)\n",
    "context = \"\\n\\n---\\n\\n\".join(chunks) if chunks else \"\"\n",
    "chat_history.append({\"role\": \"user\", \"content\": context + \"\\n\" + query})\n",
    "assistant_response, chat_history = stream_chat_response(OLLAMA_MODEL, chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e085964-aef0-4e18-b6f4-26b7227f6a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best teacher of class10_english'},\n",
       " {'role': 'user',\n",
       "  'content': 'Given below is a poem written by Norman Littleford, which\\nmay help you think and compose.\\n10 Words and ExprEssions 2 ‚Äì Class x\\nReprint 2025-26\\nUnit-1.indd 10 27-Jun-2019 04:21:16 PM\\n\\n---\\n\\nbelow.\\nand can cheat anyone.\\n# give space\\n(i) Lencho _______________________ thought God would help . put a full stop\\n, insert comma\\n^\\nhim.\\ninsert new word\\n(j) Those ____________________________ will succeed.\\nSee page nos\\n140-141 for more\\n(k) God helps those ______________________________\\nsuch symbols.\\nReprint 2025-26\\nUnit-1.indd 7 6/25/2024 12:25:45 PM\\n\\n---\\n\\ne\\nditinG\\n1. Suppose Lencho gets a hundred pesos in his envelope. He\\nwrites a letter to God expressing his gratitude. However, he\\nhas missed a word in each line. Help him with those words\\nso that his letter is complete.\\nDear God!\\nThank for Thank you for\\n(a) sending a hundred pesos help. _______________\\n(b) I am very for this kind gesture. _______________\\n(c) You were my only and your _______________\\n(d) help has my faith in you. _______________\\nShow me the full poem'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Here is the complete poem with the missing words filled in:\\n\\n**Lencho's Letter to God**\\n\\nDear God!\\n\\nThank for Thank you for\\n(a) sending a hundred pesos help.\\n(b) I am very grateful for this kind gesture.\\n(c) You were my only and your love.\\n(d) help has strengthened my faith in you.\\n\\nAnd here is the complete poem with all the missing words filled in:\\n\\n**The Missing Words**\\n\\n(i) Lencho thought that God would help him.\\n\\n(j) Those who believe will succeed.\\n\\n(k) God helps those who are true believers.\\n\\nI hope this helps!\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd654b-64e4-4b64-95ec-613f231a8206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
